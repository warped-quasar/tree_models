{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode dataset with categorical variables to be used in a tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define working directory and file input names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_output_path_string():\n",
    "    \"\"\"Dynamically build the ouput file string name to include the date at the end\n",
    "    \"\"\"\n",
    "    suffix = datetime.today().strftime('%m%d%Y')\n",
    "    out_path = f'preprocessed_tree_model_data_{suffix}.csv'\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define filenames and CWD as variable\n",
    "working_directory = r\"C:\\Users\\nick_simmons\\Mitel\"\n",
    "input_file_name = 'ModelingTrainingSet.csv'\n",
    "out_path = build_output_path_string()\n",
    "full_input_path = os.path.join(working_directory, input_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your working directory is: C:\\Users\\nick_simmons\\Mitel\n",
      "\n",
      "Input file name: ModelingTrainingSet.csv\n",
      "\n",
      "Binarized output file name: preprocessed_tree_model_data_06242019.csv\n"
     ]
    }
   ],
   "source": [
    "# ensure you are working in the right directory\n",
    "os.chdir(working_directory)\n",
    "print(f'Your working directory is: {os.getcwd()}\\n')\n",
    "print(f'Input file name: {input_file_name}\\n')\n",
    "print(f'Binarized output file name: {out_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Steps\n",
    "1. Import data as Pandas DataFrame\n",
    "2. Remove the target variable, selected variables, and continuous variables from the df. \n",
    "3. Binarize the remaining fields in the dataframe\n",
    "4. Rebuild the excluded continuous and target fields\n",
    "5. Stitch the target, binarized and continuous dataframes into one single dataframe\n",
    "6. Write the output dataframe as a csv file using the path string defined in the function: build_output_path_string()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare dataset specific variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_input_path = r'C:\\Users\\nick_simmons\\Mitel\\ModelingTrainingSet.csv'\n",
    "fields_to_drop =  ['ttc_buckets', 'Total Pipeline']\n",
    "continuous_fields = ['Opportunity: Total # of Products', 'TTC']\n",
    "target = 'Opportunity: Won'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and remove target, continuous, and user selected fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_df(full_input_path):\n",
    "    \"\"\"Read in a DataFrame from a csv using pandas\n",
    "    \"\"\"\n",
    "    return pd.read_csv(full_input_path, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_target(df, target):\n",
    "    \"\"\"Remove the target variable from the list of variables to define\n",
    "    \"\"\"\n",
    "    return df.drop(columns=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_selected_fields(df, fields_to_drop):\n",
    "    \"\"\"Create a list of user selected fields to remove from the dataset\n",
    "    A helper function to allow the user to remove a list of selected columns\n",
    "    \"\"\"\n",
    "    return df.drop(columns=fields_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_continuous_fields(df, continuous_fields):\n",
    "    \"\"\"Input a list of continuous fields to remove from the dataset\n",
    "    \"\"\"\n",
    "    return df.drop(columns=continuous_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarize remaining fields by running all of the remove functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_ready_df(df):\n",
    "    \"\"\"Use pandas built in function get_dummies to binarize all categorical variables\n",
    "    \"\"\"\n",
    "    return pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binarized_df(full_input_path, target, fields_to_drop, continuous_fields):\n",
    "    \"\"\"Run all the 'remove functions' before binarizing the remaining categorical variables\n",
    "    \"\"\"\n",
    "    input_df = import_df(full_input_path)\n",
    "    df_remove_target = remove_target(input_df, target)\n",
    "    df_remove_selected = remove_selected_fields(df_remove_target, fields_to_drop)\n",
    "    df_remove_selected_and_continuous = remove_continuous_fields(df_remove_selected, continuous_fields)\n",
    "    binarized_df = binarize_ready_df(df_remove_selected_and_continuous)\n",
    "    return binarized_df\n",
    "binarized_df = get_binarized_df(full_input_path, target, fields_to_drop, continuous_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build DataFrames for selected, continuous and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target_df(target):\n",
    "    \"\"\"Build a new df that only contains the target variable\n",
    "    \"\"\"\n",
    "    input_df = import_df(full_input_path)\n",
    "    return input_df[target]\n",
    "\n",
    "target_df = create_target_df(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_continuous_df(continuous_fields):\n",
    "    \"\"\"Create a new df that only contains the variables defined as continuous\n",
    "    \"\"\"\n",
    "    input_df = import_df(full_input_path)\n",
    "    continuous_fields_df = input_df[continuous_fields]\n",
    "    return continuous_fields_df\n",
    "\n",
    "continuous_fields_df = create_continuous_df(continuous_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate target, binarized, and continuous DataFrames into one output DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_dfs_together(target_df, binarized_df, continuous_fields_df):\n",
    "    \"\"\"Concatenate the target_df, binarized_df, continuous_fields_df to create a single output dataframe\n",
    "    \"\"\"\n",
    "    dfs_list = [target_df, binarized_df, continuous_fields_df]\n",
    "    stiched_df = pd.concat(dfs_list, axis=1)\n",
    "    return stiched_df\n",
    "\n",
    "stiched_df = stitch_dfs_together(binarized_df, target_df, continuous_fields_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(out_df):\n",
    "    '''If the output file doesn't exist write to a csv else warn user that the file already exists\n",
    "    '''\n",
    "    if os.path.isfile(out_path):\n",
    "        print('That file already exists, please change the output file name')\n",
    "    else:\n",
    "        print(f\"File does not exist yet, writing new csv named: {out_path}\")\n",
    "        out_df.to_csv(out_path, mode='x', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the main function and run the entire script from end to end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    binarized_df = get_binarized_df(full_input_path, target, fields_to_drop, continuous_fields)\n",
    "    out_df = stitch_dfs_together(binarized_df, target_df, continuous_fields_df)\n",
    "    write_csv(out_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File does not exist yet, writing new csv named: preprocessed_tree_model_data_06242019.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}